{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -1. -1. -1. -1.]\n",
      " [-1.  0. -1. -1. -1. -1.]\n",
      " [-1. -1.  0. -1. -1. -1.]\n",
      " [-1. -1. -1.  0. -1. -1.]\n",
      " [-1. -1. -1. -1.  0. -1.]\n",
      " [-1. -1. -1. -1. -1.  0.]]\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1.  0. -1. -1.]\n",
      " [-1. -1.  0. -1.]\n",
      " [-1. -1. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from causallearn.utils.cit import CIT\n",
    "\n",
    "def check_sepset(X, Y, Z, sepsets):\n",
    "    \"\"\"\n",
    "    Check if Y is in the separation set for nodes X and Z.\n",
    "    \"\"\"\n",
    "    return Z in sepsets.get((X, Y), [])\n",
    "\n",
    "def adjacent_nodes(node, adjacency):\n",
    "    \"\"\"\n",
    "    List all nodes adjacent to the given node in the adjacency matrix.\n",
    "    \"\"\"\n",
    "    return [idx for idx, connected in enumerate(adjacency[node]) if connected == 1]\n",
    "\n",
    "def perform_pc_algorithm(dataframe):\n",
    "    labels = dataframe.columns.tolist()\n",
    "    label_indices = {label: idx for idx, label in enumerate(labels)}\n",
    "    # Task 1\n",
    "    num_vars = len(labels)\n",
    "    data = dataframe.to_numpy()\n",
    "    adjacency = -np.ones((num_vars, num_vars))\n",
    "    np.fill_diagonal(adjacency, 0)\n",
    "\n",
    "    cit_test = CIT(data, \"fisherz\")\n",
    "    sepsets = {}\n",
    "    # Task 2\n",
    "    for size in range(num_vars - 2):\n",
    "        updated = False\n",
    "        for i in range(num_vars):\n",
    "            for j in adjacent_nodes(i, adjacency):\n",
    "                if j > i:\n",
    "                    common_adj = set(adjacent_nodes(i, adjacency)) & set(adjacent_nodes(j, adjacency))\n",
    "                    if len(common_adj) >= size:\n",
    "                        for subset in combinations(common_adj, size):\n",
    "                            if cit_test(i, j, list(subset)) > alpha:\n",
    "                                adjacency[i][j] = adjacency[j][i] = 0\n",
    "                                sepsets[(i, j)], sepsets[(j, i)] = list(subset), list(subset)\n",
    "                                updated = True\n",
    "        if not updated:\n",
    "            break\n",
    "\n",
    "    # Task 3 \n",
    "    for i in range(num_vars):\n",
    "        for j in adjacent_nodes(i, adjacency):\n",
    "            for k in adjacent_nodes(j, adjacency):\n",
    "                if k != i and adjacency[i][k] == 0 and not check_sepset(i, k, j, sepsets):\n",
    "                    adjacency[i][j], adjacency[j][k] = 1, 1\n",
    "                    adjacency[j][i], adjacency[k][j] = 0, 0\n",
    "\n",
    "    # Task 4\n",
    "    while True:\n",
    "        changed = False\n",
    "        for i in range(num_vars):\n",
    "            for j in range(num_vars):\n",
    "                if adjacency[i][j] == 1:  # Directed i -> j\n",
    "                    for k in adjacent_nodes(j, adjacency):\n",
    "                        if k != i and adjacency[j][k] == -1 and adjacency[i][k] == 0:\n",
    "                            adjacency[j][k], adjacency[k][j] = 1, 0\n",
    "                            changed = True\n",
    "                        if adjacency[k][i] == 1 and adjacency[k][j] == -1:\n",
    "                            adjacency[k][j], adjacency[j][k] = 1, 0\n",
    "                            changed = True\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return adjacency\n",
    "\n",
    "# Example usage:\n",
    "np.random.seed(0)\n",
    "n_samples = 2000\n",
    "std_dev = np.sqrt(0.8)\n",
    "X1, X3, X4 = [np.random.normal(0, std_dev, n_samples) for _ in range(3)]\n",
    "X2 = 0.5 * X1 + np.random.normal(0, std_dev, n_samples)\n",
    "X5 = 0.5 * X2 + 0.5 * X3 + 0.5 * X4 + np.random.normal(0, std_dev, n_samples)\n",
    "X6 = 0.5 * X5 + np.random.normal(0, std_dev, n_samples)\n",
    "\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3, 'X4': X4, 'X5': X5, 'X6': X6})\n",
    "alpha = 0.05\n",
    "adj_matrix = perform_pc_algorithm(df)\n",
    "print(adj_matrix)\n",
    "\n",
    "# Additional usage with real data\n",
    "data_path = '/home/minghao.fu/workspace/Homework/ML803/week12/dataverse_files/galton-stata11.dta'\n",
    "galton_data = pd.read_stata(data_path)\n",
    "relevant_data = galton_data[['father', 'mother', 'gender', 'height']].copy()\n",
    "relevant_data['gender_encoded'] = LabelEncoder().fit_transform(relevant_data['gender'])\n",
    "\n",
    "data_for_pc = relevant_data[['father', 'mother', 'gender_encoded', 'height']]\n",
    "adjacency_result = perform_pc_algorithm(data_for_pc)\n",
    "print(adjacency_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
